import requests
from bs4 import BeautifulSoup
import csv 
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager

service = Service(ChromeDriverManager().install())
options = webdriver.ChromeOptions()
options.add_argument("--headless") 
get_comments = webdriver.Chrome(service=service, options=options)
       

page = requests.get("https://www.flo.com.tr/ayakkabi?cinsiyet=kadin")

def main(page):
    
    # Sayfanın içeriğini çarmak 
    src = page.content 
    # lxlm formatına yani anlayabileceğimiz kod parçasına dönüştürüldü
    soup = BeautifulSoup(src, "lxml")
    # Product details : ürünlerin detaylarını kaydetmak için oluşturuldu
    product_details = []
    # Ürünler çağırıldı
    products = soup.find_all('div', {'class' : 'js-product-vertical'})
    number_of_product = len(products)
    print("Ürün sayısı:" ,number_of_product)
    #comment-star__button 
    #.get('data-product-id')
    #.find('div', {'class': 'comment-star__button'})
    def get_product_info(product):
        
          # Ürün numarası ve ürün id 
          product_num = product.get('data-product-sku-zero-except')
          find_product_id = product.find('div', {'class': 'comment-star__button'})
          if find_product_id is not None:
              product_id = find_product_id.get('data-product-id')
          else:
              product_id = "00000"   # Default

          print(product_id)

          # Ürün adı
          product_name = product.find('span',{'class': 'product__name-brand'}).text.strip()

          # Ürün kategorisi
          product_cat = product.find('span',{'class': 'product__name-description'}).text.strip()
          if "Kadın" in product_cat:
              gender = "Kadın"
          elif "Unisex" in product_cat:
              gender = "Unisex"
         
        #  print(product_num,"-",product_id,"-", product_name,"-",gender)    
    
          # Yorumlara erişmek,json kullanıldığı için Selenium webdriver ile erişildi
          get_comments.get(f"https://www.flo.com.tr/productComments?product_id={product_id}")
          # Selenium için tekrar parse edildi       
          src1 = get_comments.page_source
          soup_comments = BeautifulSoup(src1, 'lxml')
         # print(product_id,"----------",soup_comments) 
          # Yorumlar
          comments_elements = soup_comments.find_all('div', {'class' : 'comment-detail__item'})
        #  print(comments_elements)
          for comments in comments_elements:
            # Yorum  
            comment_text = comments.find('p', {'class': 'product-rating-comment-item'}).text.strip()
            if comment_text == None:
                comment_text = ""
            # Yorum Tarihi
            comment_date = comments.find('div', {'class': 'comment-date'}).text.strip()
            if comment_date == None:
                comment_date = ""
                
            product_details.append({"Ürün numarası" : product_num, "Ürün ID" : product_id, "Ürün adı" : product_name,
            "Ürün kategorisi" :  gender,"Yorum text":comment_text, "Yorum tarihi" : comment_date})      

    for product in products :     
        get_product_info(product)  
    # Csv de ki tablonun başlıkları sadece, product_details den alındı
    keys = product_details[0].keys()

    with open('C:\\Users\\marir\\OneDrive\\Desktop\\FloProjesi\\Web Scraping\\FloKadin.csv', 'w',  newline='',  encoding='utf-8') as output_file:
        dict_writer = csv.DictWriter(output_file, keys)
        dict_writer.writeheader()
        for product in product_details:
            dict_writer.writerow(product)
   
        print('File Created')

          
main(page)    

